universe = vanilla
executable = data_pipeline.sh

log = logs/data_pipeline.log
output = logs/data_pipeline_$(Cluster).out
error = logs/data_pipeline_$(Cluster).err

transfer_input_files = data_inputs/

should_transfer_files = YES
when_to_transfer_output = ON_EXIT

Requirements = (Target.HasCHTCStaging == true)

if defined USE_SMALL_DB
  # testing requirements
  request_memory = 8GB
  request_disk = 16GB
  request_cpus = 4
  arguments = 1 1
else
  # full requirements
  request_memory = 8GB
  request_disk = 700GB
  request_cpus = 8
  arguments = 1 0
endif

queue


